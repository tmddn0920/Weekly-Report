# 2025.11.13

## 1. 논문 리뷰

이번 주에는 HLASD 관련 최신 논문을 검토를 진행했습니다.

또한, 이전에 공유받은 주파수 기반 Attention 및 스펙트럼 관련 이론도 복습하여, 향후 연구 설계에 필요한 기초를 확립했습니다.

## SegFormer + CamVid 실험 진행

SegFormer의 pretrained weight를 적용하여 CamVid 데이터셋에 대한 Semantic Segmentation 실험을 진행했습니다.
다만, 실험 환경 구축에 예상보다 많은 시간이 소요되어 전체 실험은 1회만 수행하였고, 그 결과 B2 모델의 성능이 기대보다 낮게 나타나는 현상을 확인했습니다.
이는 CamVid의 데이터 규모 및 iteration 부족의 영향이 있을 것으로 보이며, iteration 확장 및 hyperparameter 수정 후 재실험이 필요할 것으로 판단됩니다.

## Knowledge Distillation 기초 실험

주간 보고 전까지 KD 과정을 이해하는 것이 우선이라고 판단하여, Teacher 모델의 성능이 다소 낮음에도 불구하고 B0 모델에 대한 Knowledge Distillation 실험을 진행했습니다.
Distillation 과정에서는 다음의 Loss들을 적용하여 기초적인 KD 파이프라인을 구축했습니다.

- KL Divergence Loss
- AT(Attention Transfer) Loss
- SP(Similarity-Preserving) Loss

이를 통해 전체 KD flow가 정상적으로 동작함을 확인했으며, 이후 Hodge Decomposition을 활용하는 KD 설계로 확장할 준비가 완료되었습니다.

---

# SegFormer Knowledge Distillation 실험 결과 분석

## 실험 개요

CamVid 데이터셋에서 SegFormer 모델을 사용하여 3가지 실험을 수행했습니다:
1. **SegFormer B0 Baseline**: 일반 학습 (Teacher 없이)
2. **SegFormer B2 Teacher**: Teacher 모델 학습
3. **SegFormer B0 Student with KD**: Knowledge Distillation을 사용한 Student 모델 학습

---

## 실험 설정

### 공통 설정
- **데이터셋**: CamVid (12 클래스)
- **이미지 크기**: 512x512
- **최대 Iteration**: 40,000
- **Evaluation Interval**: 4,000 iterations
- **Optimizer**: AdamW
- **Learning Rate**: 0.00003 (선형 스케일링: 1 GPU × 4 img/gpu = 4)
- **LR Schedule**: Poly (warmup 1,500 iterations)
- **Batch Size**: 4 (samples_per_gpu)
- **Workers**: 4 (workers_per_gpu)
- **Normalization**: BN (BatchNorm, Windows 단일 GPU 환경)

### 실험별 상세 설정

#### 1. SegFormer B0 Baseline
- **설정 파일**: `local_configs/segformer/B0/segformer.b0.512x512.camvid.py`
- **모델**: EncoderDecoder (SegFormer B0)
- **Backbone**: mit_b0
- **Pretrained**: `pretrained/mit_b0.pth`
- **Loss**: CrossEntropyLoss (loss_weight=1.0)
- **Work Dir**: `work_dirs/segformer_b0_camvid_baseline`

#### 2. SegFormer B2 Teacher
- **설정 파일**: `local_configs/segformer/B2/segformer.b2.512x512.camvid.py`
- **모델**: EncoderDecoder (SegFormer B2)
- **Backbone**: mit_b2
- **Pretrained**: `pretrained/mit_b2.pth`
- **Loss**: CrossEntropyLoss (loss_weight=1.0)
- **Work Dir**: `work_dirs/segformer_b2_camvid_teacher`

#### 3. SegFormer B0 Student with KD
- **설정 파일**: `local_configs/segformer/B0/segformer.b0.512x512.camvid.kd.py`
- **모델**: KDEncoderDecoder (SegFormer B0)
- **Backbone**: mit_b0
- **Pretrained**: `pretrained/mit_b0.pth`
- **Teacher**: SegFormer B2 (from `work_dirs/segformer_b2_camvid_teacher/iter_40000.pth`)
- **KD Losses**:
  - KL Divergence Loss: temperature=4.0, loss_weight=1.0
  - Attention Transfer Loss: loss_weight=1.0
  - Similarity Preserving Loss: loss_weight=1.0
- **Work Dir**: `work_dirs/segformer_b0_camvid_student_kd`

---

## 실험 결과

### 전체 성능 비교

| 모델 | Best mIoU | Best Iter | Best mAcc | Best aAcc | Final mIoU | Final Iter |
|------|----------|-----------|-----------|-----------|------------|------------|
| **B0 Baseline** | **67.94%** | 32,000 | 76.09% | 91.09% | 67.78% | 40,000 |
| **B2 Teacher** | 64.09% | 40,000 | 71.75% | 90.23% | 64.09% | 40,000 |
| **B0 Student (KD)** | 67.13% | 36,000 | 76.18% | 90.49% | 67.08% | 40,000 |

### 상세 결과

#### 1. SegFormer B0 Baseline

| Iteration | mIoU | mAcc | aAcc | Learning Rate |
|-----------|------|------|------|---------------|
| 4,000 | 58.62% | 68.53% | 87.37% | 3e-05 |
| 8,000 | 62.42% | 70.84% | 88.48% | 2e-05 |
| 12,000 | 64.04% | 72.01% | 89.43% | 2e-05 |
| 16,000 | 65.53% | 74.69% | 89.99% | 2e-05 |
| 20,000 | 65.99% | 74.69% | 90.12% | 2e-05 |
| 24,000 | 66.38% | 76.30% | 90.65% | 1e-05 |
| 28,000 | 66.50% | 75.99% | 90.67% | 1e-05 |
| **32,000** | **67.94%** | **76.09%** | **91.09%** | **1e-05** |
| 36,000 | 67.51% | 76.22% | 90.98% | 0.0 |
| 40,000 | 67.78% | 76.42% | 91.16% | 0.0 |

**Best 결과**: Iteration 32,000에서 **mIoU 67.94%** 달성

#### 2. SegFormer B2 Teacher

| Iteration | mIoU | mAcc | aAcc | Learning Rate |
|-----------|------|------|------|---------------|
| 4,000 | 41.75% | 51.71% | 80.52% | 3e-05 |
| 8,000 | 48.63% | 56.93% | 85.18% | 2e-05 |
| 12,000 | 55.03% | 62.63% | 86.82% | 2e-05 |
| 16,000 | 56.70% | 64.50% | 87.40% | 2e-05 |
| 20,000 | 57.50% | 65.42% | 87.29% | 2e-05 |
| 24,000 | 58.71% | 69.10% | 88.08% | 1e-05 |
| 28,000 | 62.30% | 69.70% | 89.85% | 1e-05 |
| 32,000 | 62.87% | 71.06% | 89.63% | 1e-05 |
| 36,000 | 63.70% | 71.52% | 90.12% | 0.0 |
| **40,000** | **64.09%** | **71.75%** | **90.23%** | **0.0** |

**Best 결과**: Iteration 40,000에서 **mIoU 64.09%** 달성

#### 3. SegFormer B0 Student with KD

| Iteration | mIoU | mAcc | aAcc | Learning Rate |
|-----------|------|------|------|---------------|
| 4,000 | 59.08% | 67.28% | 86.96% | 3e-05 |
| 8,000 | 63.11% | 72.85% | 89.20% | 2e-05 |
| 12,000 | 63.94% | 73.23% | 89.17% | 2e-05 |
| 16,000 | 65.10% | 74.64% | 89.30% | 2e-05 |
| 20,000 | 65.83% | 74.60% | 89.97% | 2e-05 |
| 24,000 | 66.59% | 75.52% | 90.40% | 1e-05 |
| 28,000 | 65.91% | 76.18% | 90.11% | 1e-05 |
| 32,000 | 66.81% | 76.14% | 90.36% | 1e-05 |
| **36,000** | **67.13%** | **76.18%** | **90.49%** | **0.0** |
| 40,000 | 67.08% | 76.01% | 90.58% | 0.0 |

**Best 결과**: Iteration 36,000에서 **mIoU 67.13%** 달성

---

## 주요 발견 사항

### 1. 성능 비교
- **B0 Baseline이 가장 높은 성능** (mIoU 67.94%)
- **B0 Student (KD)는 Baseline보다 약간 낮음** (mIoU 67.13%, 약 0.81%p 차이)
- **B2 Teacher는 예상보다 낮은 성능** (mIoU 64.09%)

### 2. 학습 패턴 분석

#### B0 Baseline
- 초기 학습이 빠르고 안정적
- Iteration 32,000에서 최고 성능 달성 후 약간 하락
- 학습률이 0으로 떨어지기 전(iteration 36,000)에 최고 성능

#### B2 Teacher
- 초기 학습이 느림 (iteration 4,000에서 41.75%)
- 학습이 진행되면서 점진적으로 개선
- 최종 iteration까지 성능 향상 지속

#### B0 Student (KD)
- 초기 학습 속도는 Baseline과 유사
- Iteration 24,000 이후 성능 향상이 둔화
- Iteration 28,000에서 일시적 하락 후 회복
- Iteration 36,000에서 최고 성능 후 약간 하락

### 3. Knowledge Distillation 효과 분석

**현재 결과**: KD를 사용한 Student 모델이 Baseline보다 성능이 낮음

**가능한 원인**:
1. **KD 손실 가중치 불균형**: 모든 KD 손실의 가중치가 1.0으로 설정되어 있어 기본 손실과의 균형이 맞지 않을 수 있음
2. **Teacher 모델 성능**: B2 Teacher의 성능(64.09%)이 B0 Baseline(67.94%)보다 낮아, Teacher로부터 학습할 지식이 제한적일 수 있음
3. **Temperature 설정**: KL Divergence의 temperature=4.0이 최적이 아닐 수 있음
4. **학습률 스케줄**: KD 손실이 추가되면서 학습률 스케줄 조정이 필요할 수 있음

---

## Best 결과 위치

### 1. B0 Baseline
- **Best mIoU**: 67.94%
- **Iteration**: 32,000
- **Checkpoint**: `work_dirs/segformer_b0_camvid_baseline/iter_32000.pth`
- **특징**: 학습률이 1e-05일 때 최고 성능 달성

### 2. B2 Teacher
- **Best mIoU**: 64.09%
- **Iteration**: 40,000
- **Checkpoint**: `work_dirs/segformer_b2_camvid_teacher/iter_40000.pth`
- **특징**: 최종 iteration에서 최고 성능

### 3. B0 Student (KD)
- **Best mIoU**: 67.13%
- **Iteration**: 36,000
- **Checkpoint**: `work_dirs/segformer_b0_camvid_student_kd/iter_36000.pth`
- **특징**: 학습률이 0.0일 때 최고 성능 달성

---

## 개선 방안

### 1. Knowledge Distillation 손실 가중치 조정

```python
kd_losses = dict(
    kl_loss=dict(type='KLDivergenceLoss', temperature=4.0, loss_weight=1.0),
    at_loss=dict(type='AttentionTransferLoss', loss_weight=1.0),
    sp_loss=dict(type='SimilarityPreservingLoss', loss_weight=1.0)
)
```

### 2. Teacher 모델 개선

**문제**: B2 Teacher의 성능(64.09%)이 B0 Baseline(67.94%)보다 낮음

**개선 방안**:
- B2 Teacher의 학습률 스케줄 조정
- 더 많은 iteration 학습 (40,000 → 60,000)
- Data augmentation 강화
- 다른 pretrained weight 사용 검토

### 3. 학습률 스케줄 조정

**개선 방안**:
- KD 학습 시 학습률을 약간 낮춤 (0.00003 → 0.00002)
- Warmup iteration 증가 (1,500 → 2,000)
- Learning rate decay를 더 부드럽게 조정

### 7. 하이퍼파라미터 탐색

**체계적 탐색 필요**:
- Grid search 또는 Bayesian optimization으로 최적 가중치 탐색
- Temperature 값 탐색
- 각 KD 손실의 개별 효과 분석

---

## 결론

1. **현재 Best 모델**: SegFormer B0 Baseline (mIoU 67.94% @ iter 32,000)
2. **KD 효과**: 현재 설정에서는 KD가 Baseline보다 성능이 낮음
3. **개선 필요**: KD 손실 가중치 조정 및 Teacher 모델 성능 향상이 필요
4. **다음 단계**: 
   - KD 손실 가중치를 낮춰서 실험 (AT, SP: 0.1 ~ 0.5)
   - B2 Teacher 모델 추가 학습 또는 다른 Teacher 모델 시도
   - Temperature 값 조정 실험

---
