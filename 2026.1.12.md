### KD Baseline

https://docs.google.com/spreadsheets/d/1AyJ_aeIM9oqE7ZXBfwS9ar6RUuLuRwbvvImQRWx36qI/edit?usp=sharing

기존 KD Baseline에 GDKD 방법론 추가했습니다.

## HodgeKD

#### 모델별 평균 성능 (K-Fold 교차 검증, Fold1/2 평균) - B2 B0 No-Pretrained

### Iteration ≤ 30000

| Model            | Building  | Bicyclist | Fence     | Pole      | Pedestrian | Road      | Sky       | SignSymbol | Tree      | Sidewalk  | Car       | **mIoU**  | **mPA**   | **aAcc**  |
| ---------------- | --------- | --------- | --------- | --------- | ---------- | --------- | --------- | ---------- | --------- | --------- | --------- | --------- | --------- | --------- |
| **B2 (Teacher)** | 86.42     | 58.14     | 64.15     | 17.58     | 36.82      | 95.51     | 87.26     | 31.89      | 76.21     | 81.28     | 79.15     | **64.94** | **72.32** | **92.14** |
| **B0 (Student)** | 83.74     | 51.47     | 54.47     | 9.66      | 27.91      | 93.99     | 86.04     | 21.62      | 73.27     | 75.84     | 73.66     | **59.24** | **66.97** | **90.52** |
| **HodgeKD**      | 83.93     | 49.51     | 56.33     | 10.12     | 27.96      | 94.07     | 86.13     | 23.76      | 73.41     | 76.14     | 73.30     | **59.51** | **67.82** | **90.58** |
| **HodgeKD_LF**   | 83.92     | 52.14     | 53.74     | 8.95      | 28.00      | 94.05     | 86.30     | 23.76      | 73.14     | 76.13     | 73.21     | **59.39** | **66.91** | **90.59** |

### Iteration ≤ 35000

| Model            | Building  | Bicyclist | Fence     | Pole      | Pedestrian | Road      | Sky       | SignSymbol | Tree      | Sidewalk  | Car       | **mIoU**  | **mPA**   | **aAcc**  |
| ---------------- | --------- | --------- | --------- | --------- | ---------- | --------- | --------- | ---------- | --------- | --------- | --------- | --------- | --------- | --------- |
| **B2 (Teacher)** | 86.42     | 58.14     | 64.15     | 17.58     | 36.82      | 95.51     | 87.26     | 31.89      | 76.21     | 81.28     | 79.15     | **64.94** | **72.32** | **92.14** |
| **B0 (Student)** | 83.74     | 51.47     | 54.47     | 9.66      | 27.91      | 93.99     | 86.04     | 21.62      | 73.27     | 75.84     | 73.66     | **59.24** | **66.97** | **90.52** |
| **HodgeKD**      | 84.35     | 52.19     | 56.66     | 10.10     | 28.43      | 94.25     | 86.10     | 25.92      | 73.92     | 76.69     | 73.82     | **60.22** | **67.80** | **90.80** |
| **HodgeKD_LF**   | 84.18     | 52.31     | 55.17     | 10.17     | 29.03      | 94.12     | 86.46     | 24.56      | 73.60     | 76.53     | 73.27     | **59.95** | **67.89** | **90.71** |

### Iteration ≤ 40000

| Model            | Building  | Bicyclist | Fence     | Pole      | Pedestrian | Road      | Sky       | SignSymbol | Tree      | Sidewalk  | Car       | **mIoU**  | **mPA**   | **aAcc**  |
| ---------------- | --------- | --------- | --------- | --------- | ---------- | --------- | --------- | ---------- | --------- | --------- | --------- | --------- | --------- | --------- |
| **B2 (Teacher)** | 86.42     | 58.14     | 64.15     | 17.58     | 36.82      | 95.51     | 87.26     | 31.89      | 76.21     | 81.28     | 79.15     | **64.94** | **72.32** | **92.14** |
| **B0 (Student)** | 83.74     | 51.47     | 54.47     | 9.66      | 27.91      | 93.99     | 86.04     | 21.62      | 73.27     | 75.84     | 73.66     | **59.24** | **66.97** | **90.52** |
| **HodgeKD**      | 84.29     | 51.90     | 57.22     | 10.62     | 28.92      | 94.31     | 86.22     | 24.66      | 73.83     | 76.78     | 74.75     | **60.32** | **67.91** | **90.84** |
| **HodgeKD_LF**   | 84.35     | 52.42     | 55.87     | 10.16     | 29.20      | 94.24     | 86.44     | 24.71      | 73.70     | 76.62     | 73.86     | **60.14** | **67.87** | **90.80** |


HLASD: Hodge Laplacian-based Simplicial Anomaly Detection 논문은 Hodge Laplacian의 상위 차원 + 하위 차원에 각각 가중치를 부여해 전체 이미지의 위상적 흐름을 분석한다.
논문에서는 Hodge Laplacian의 상위 차원(Curl) -> 순환적 관계, 형태적 위상, Hodge Laplacian의 하위 차원(Gradient) -> 급격한 변화, 자역적 위상, Curl + Gradient의 변화는 곧 전역적 맥락인 Harmonic(조화)에 영향을 준다고 분석하고 있다.
Image Segmentation의 경우 전역적 맥락을 담당하는 Harmonic 역시 중요하기 때문에, Curl + Gradient + Harmonic을 모두 KD에 활용해야 한다고 가정했다.

이런 스펙트럼 그래프를 어떻게 적용하면 좋을 지는 Frequency Attetntion for Knowledge Distillation 논문에서 아이디어를 받았는데, Student에 단순 1 X 1 Convolution을 진행해 Teacher 모델과 채널을 맞춘 후, 위상적 정보가 아닌 공간적 정보를 전달할 수 있는 Branch, Hodge Decomposition을 적용해 위상적 정보를 전달할 수 있는 Branch로 나눈 후, 각각 학습 가능한 파라미터를 부여하는 방식이 좋을 거 같다는 생각이 들었다. 

우선 가장 처음 떠올린 아이디어이다.

<img width="1219" height="682" alt="스크린샷 2026-01-12 오후 3 37 00" src="https://github.com/user-attachments/assets/8b6967eb-79db-456f-a402-b4a1e5fb2c93" />

공간적 정보를 전달하는 경로는 단순 MSE를 활용하였다.

위상적 정보를 전달하기 위한 Hodge Decomposition의 경우 입력 Feature을 미분해서 벡터장을 만든 후, FFT를 바탕으로 벡터의 전위차, 전위를 각각 구해 Gradient, Curl 성분을 구하고 원래의 벡터장에서 Gradient, Curl을 빼서 Harmonic 성분을 추출했다.
그 후, 우선 변화가 얼마나 큰 지, 순환이 얼마나 큰 지를 전달하는 게 중요하다 생각해서 각각 크기를 계산해 단순 MSE로 KD에 사용하였는데, 향후 크기를 사용하는 게 아니라 **X, Y 성분을 그대로 살려 직접 Teacher와 비교하는 방식**을 사용해 볼 필요도 있을 거 같다.

최종 KD Loss에는 파라미터가 음수가 되는 걸 방지하기 위해 지수를 활용하였다. 이 방법으로 훈련을 진행했을 때 HodgeKD_LF라는 결과가 나왔다.

그런데, 그냥 단순히 Linear Fuse를 한 후 Feature Map을 사용하는 건, 서로 다른 특징을 가진 Feature Map들을 이미 결합한 후 KD를 적용하는 방법이기 때문에 최신 KD 논문들과는 조금 거리가 있다는 생각이 들어 우선 같은 방법을 Linear Fuse 전 Concatenation만 진행했을 때


