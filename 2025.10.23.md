## (2025.10.23) 주간 보고

시험 기간이라 많은 공부를 진행하지는 못했지만
**Segformer + ViT**(논문 정독 후 논문 리뷰 작성 중)
**LLM-Guided Latent Semantic Augmentation: Efficient and Lightweight Training for Wearable Sensor Data**
논문 정독 완료했습니다.

전에 공부했던 Mix-Up in Knowledge Distillation 관련 정리글입니다.

https://velog.io/@tmddn0920/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-Understanding-the-Role-of-Mixup-in-Knowledge-Distillation-An-Empirical-Study

비슷한 느낌으로 Segformer + ViT 내용도 스스로 한번 더 복습하면서 작성하고 있습니다.

추가적으로 KD 관련해서 기초부터 이해하고 싶다는 생각이 들어서
Distilling the Knowledge in a Neural Network도 개인적으로 읽어 보았습니다.